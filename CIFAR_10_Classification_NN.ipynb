{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10 Classification NN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0295163e1e840cc95d51ca05b586fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5265aea944284a9ab9d1a78342420dc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d016bab8db77450aa724d43d46b92e6d",
              "IPY_MODEL_8e9b46b799bb43c3b52db5f2bbfa5333"
            ]
          }
        },
        "5265aea944284a9ab9d1a78342420dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d016bab8db77450aa724d43d46b92e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af85552da253486c9befa434e86092d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e11f1c0213a942959c87ec276be8fd15"
          }
        },
        "8e9b46b799bb43c3b52db5f2bbfa5333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6de57932e6cf4e619443d19623b06efa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 102669261.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e8752a340464f0f96d948aac0b51920"
          }
        },
        "af85552da253486c9befa434e86092d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e11f1c0213a942959c87ec276be8fd15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6de57932e6cf4e619443d19623b06efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e8752a340464f0f96d948aac0b51920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nashapir/Vision-Projects/blob/main/CIFAR_10_Classification_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix5dQS2rUMlu"
      },
      "source": [
        "# CIFAR-10 Classification NN\n",
        "\n",
        "We manually develop a two Layer neural network with fully-connected layers to perform classification, and test it out on the CIFAR-10 dataset. We train the network with a softmax loss function on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture:\n",
        "\n",
        "input - fully connected layer - ReLU - fully connected layer - softmax\n",
        "\n",
        "The outputs of the second fully-connected layer are the scores for each class. This is all done without the use of any deep learning libraries such as PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Cst4k4tuBc"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHumIO-xt57H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "d0295163e1e840cc95d51ca05b586fd3",
            "5265aea944284a9ab9d1a78342420dc2",
            "d016bab8db77450aa724d43d46b92e6d",
            "8e9b46b799bb43c3b52db5f2bbfa5333",
            "af85552da253486c9befa434e86092d7",
            "e11f1c0213a942959c87ec276be8fd15",
            "6de57932e6cf4e619443d19623b06efa",
            "6e8752a340464f0f96d948aac0b51920"
          ]
        },
        "outputId": "5bcfdbe8-1374-467a-f1aa-0f312a273d61"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision.datasets import CIFAR10\n",
        "download = not os.path.isdir('cifar-10-batches-py')\n",
        "dset_train = CIFAR10(root='.', download=download)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0295163e1e840cc95d51ca05b586fd3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXfumCQ21JoK"
      },
      "source": [
        "#Layers\n",
        "We implement fully connected layer, relu and softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-ljfgMv9PHx"
      },
      "source": [
        "def fc_forward(X, W, b):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a fully-connected layer.\n",
        "    \n",
        "    The input X has shape (N, Din) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (Din,).\n",
        "    \n",
        "    Inputs:\n",
        "    - X: A numpy array containing input data, of shape (N, Din)\n",
        "    - W: A numpy array of weights, of shape (Din, Dout)\n",
        "    - b: A numpy array of biases, of shape (Dout,)\n",
        "    \n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, Dout)\n",
        "    - cache: (X, W, b)\n",
        "    \"\"\"\n",
        "    dot_result = np.dot(X, W)\n",
        "    out = dot_result + b\n",
        "    cache = (X, W, b)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def fc_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for a fully_connected layer.\n",
        "    \n",
        "    Inputs:\n",
        "    - dout: Upstream derivative, of shape (N, Dout)\n",
        "    - cache: returned by your forward function. Tuple of:\n",
        "      - X: Input data, of shape (N, Din)\n",
        "      - W: Weights, of shape (Din, Dout)\n",
        "      - b: Biases, of shape (Dout,)\n",
        "      \n",
        "    Returns a tuple of:\n",
        "    - dX: Gradient with respect to X, of shape (N, Din)\n",
        "    - dW: Gradient with respect to W, of shape (Din, Dout)\n",
        "    - db: Gradient with respect to b, of shape (Dout,)\n",
        "    \"\"\"\n",
        "    X, W, b = cache\n",
        "    dX, dW, db = None, None, None\n",
        "    dX = np.dot(dout, W.T)\n",
        "    dW = np.dot(X.T, dout)\n",
        "    db = dout\n",
        "    return dX, dW, db\n",
        "\n",
        "def relu_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - x: Inputs, of any shape\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output, of the same shape as x\n",
        "    - cache: x\n",
        "    \"\"\"\n",
        "    out = x\n",
        "    out = np.maximum(0, out)\n",
        "    cache = x\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def relu_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - dout: Upstream derivatives, of any shape\n",
        "    - cache: returned by your forward function. Input x, of same shape as dout\n",
        "\n",
        "    Returns:\n",
        "    - dx: Gradient with respect to x\n",
        "    \"\"\"\n",
        "    dx, x = dout, cache\n",
        "    dx[x < 0] = 0\n",
        "    return dx\n",
        "\n",
        "\n",
        "def softmax_loss(X, y):\n",
        "    \"\"\"\n",
        "    Computes the loss and gradient for softmax classification.\n",
        "\n",
        "    Inputs:\n",
        "    - X: Input data, of shape (N, C) where x[i, j] is the score for the jth\n",
        "      class for the ith input.\n",
        "    - y: Vector of labels, of shape (N,) where y[i] is the label for X[i] and\n",
        "      0 <= y[i] < C\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - loss: Scalar giving the loss\n",
        "    - dX: Gradient of the loss with respect to x\n",
        "    \"\"\"\n",
        "    loss, dX = None, None                                         #\n",
        "    dX = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "    dX /= np.sum(dX, axis=1, keepdims=True)\n",
        "    loss = -np.sum(np.log(dX[np.arange(X.shape[0]), y])) / X.shape[0]\n",
        "    dX[np.arange(X.shape[0]), y] -= 1\n",
        "    dX /= X.shape[0]\n",
        "\n",
        "    return loss, dX"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFxtS3zK8oz"
      },
      "source": [
        "#Softmax Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytvxbx9UpxVL"
      },
      "source": [
        "class SoftmaxClassifier(object):\n",
        "    \"\"\"\n",
        "    A fully-connected neural network with\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecture should be fc - relu - fc - softmax with one hidden layer\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=3072, hidden_dim=300, num_classes=10,\n",
        "                 weight_scale=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize a new network.\n",
        "\n",
        "        Inputs:\n",
        "        - input_dim: An integer giving the size of the input\n",
        "        - hidden_dim: An integer giving the size of the hidden layer, None\n",
        "          if there's no hidden layer.\n",
        "        - num_classes: An integer giving the number of classes to classify\n",
        "        - weight_scale: Scalar giving the standard deviation for random\n",
        "          initialization of the weights.\n",
        "        \"\"\"\n",
        "        self.params = {}\n",
        "        self.params['W1'] = np.random.normal(0, weight_scale, size=(input_dim, hidden_dim))\n",
        "        self.params['W2'] = np.random.normal(0, weight_scale, size=(hidden_dim, num_classes))\n",
        "        self.params['b1'] = np.zeros(hidden_dim)\n",
        "        self.params['b2'] = np.zeros(num_classes)\n",
        "\n",
        "\n",
        "    def forwards_backwards(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Compute loss and gradient for a minibatch of data.\n",
        "\n",
        "        Inputs:\n",
        "        - X: Array of input data of shape (N, Din)\n",
        "        - y: Array of labels, of shape (N,). y[i] gives the label for X[i].\n",
        "\n",
        "        Returns:\n",
        "        If y is None, then run a test-time forward pass of the model and return:\n",
        "        - scores: Array of shape (N, C) giving classification scores, where\n",
        "          scores[i, c] is the classification score for X[i] and class c.\n",
        "\n",
        "        If y is not None, then run a training-time forward and backward pass. And\n",
        "        return a tuple of:\n",
        "        - loss: Scalar value giving the loss\n",
        "        - grads: Dictionary with the same keys as self.params, mapping parameter\n",
        "          names to gradients of the loss with respect to those parameters.\n",
        "        \"\"\"\n",
        "        scores = None\n",
        "        fc1_out, fc1_cache = fc_forward(X, self.params['W1'], self.params['b1'])\n",
        "        relu_out, relu_cache = relu_forward(fc1_out)\n",
        "        scores, fc2_cache = fc_forward(relu_out, self.params['W2'], self.params['b2'])\n",
        "\n",
        "        # If y is None then we are in test mode so just return scores\n",
        "        if y is None:\n",
        "            return scores\n",
        "\n",
        "        loss, grads = 0, {}\n",
        "        loss, softmax_dx = softmax_loss(scores, y)\n",
        "        fc2_back, grads['W2'], grads['b2'] = fc_backward(softmax_dx, fc2_cache)\n",
        "        relu_back = relu_backward(fc2_back, relu_cache)\n",
        "        fc1_back, grads['W1'], grads['b1'] = fc_backward(relu_back, fc1_cache)\n",
        "\n",
        "        return loss, grads\n",
        "\n",
        "  \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwp0waIL1h_e"
      },
      "source": [
        "# Training\n",
        "\n",
        "Here, we preprocess the images and set up model hyperparameters. Adjusting the training and val split is optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZPtQzXGMoCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d5723c-1e28-4ad0-921c-90d0dcfbfe10"
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding=\"latin1\")\n",
        "    return dict\n",
        "\n",
        "def load_cifar10():\n",
        "    data = {}\n",
        "    meta = unpickle(\"cifar-10-batches-py/batches.meta\")\n",
        "    batch1 = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
        "    batch2 = unpickle(\"cifar-10-batches-py/data_batch_2\")\n",
        "    batch3 = unpickle(\"cifar-10-batches-py/data_batch_3\")\n",
        "    batch4 = unpickle(\"cifar-10-batches-py/data_batch_4\")\n",
        "    batch5 = unpickle(\"cifar-10-batches-py/data_batch_5\")\n",
        "    test_batch = unpickle(\"cifar-10-batches-py/test_batch\")\n",
        "    X_train = np.vstack((batch1['data'], batch2['data'], batch3['data'],\\\n",
        "                         batch4['data'], batch5['data']))\n",
        "    Y_train = np.array(batch1['labels'] + batch2['labels'] + batch3['labels'] + \n",
        "                       batch4['labels'] + batch5['labels'])\n",
        "    X_test = test_batch['data']\n",
        "    Y_test = test_batch['labels']\n",
        "    \n",
        "    #Preprocess images here                                     \n",
        "    X_train = (X_train-np.mean(X_train,axis=1,keepdims=True))/np.std(X_train,axis=1,keepdims=True)\n",
        "    X_test = (X_test-np.mean(X_test,axis=1,keepdims=True))/np.std(X_test,axis=1,keepdims=True)\n",
        "\n",
        "    data['X_train'] = X_train[:40000]\n",
        "    data['y_train'] = Y_train[:40000]\n",
        "    data['X_val'] = X_train[40000:]\n",
        "    data['y_val'] = Y_train[40000:]\n",
        "    data['X_test'] = X_test\n",
        "    data['y_test'] = Y_test\n",
        "    return data\n",
        "\n",
        "def testNetwork(model, X, y, num_samples=None, batch_size=100):\n",
        "    \"\"\"\n",
        "    Check accuracy of the model on the provided data.\n",
        "\n",
        "    Inputs:\n",
        "    - model: Image classifier\n",
        "    - X: Array of data, of shape (N, d_1, ..., d_k)\n",
        "    - y: Array of labels, of shape (N,)\n",
        "    - num_samples: If not None, subsample the data and only test the model\n",
        "      on num_samples datapoints.\n",
        "    - batch_size: Split X and y into batches of this size to avoid using\n",
        "      too much memory.\n",
        "\n",
        "    Returns:\n",
        "    - acc: Scalar giving the fraction of instances that were correctly\n",
        "      classified by the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Subsample the data\n",
        "    N = X.shape[0]\n",
        "    if num_samples is not None and N > num_samples:\n",
        "        mask = np.random.choice(N, num_samples)\n",
        "        N = num_samples\n",
        "        X = X[mask]\n",
        "        y = y[mask]\n",
        "\n",
        "    # Compute predictions in batches\n",
        "    num_batches = N // batch_size\n",
        "    if N % batch_size != 0:\n",
        "        num_batches += 1\n",
        "    y_pred = []\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        scores = model.forwards_backwards(X[start:end])\n",
        "        y_pred.append(np.argmax(scores, axis=1))\n",
        "    y_pred = np.hstack(y_pred)\n",
        "    acc = np.mean(y_pred == y)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def SGD(W,dW, learning_rate=1e-3):\n",
        "    \"\"\" Apply a gradient descent step on weight W \n",
        "    Inputs:\n",
        "        W : Weight matrix\n",
        "        dW : gradient of weight, same shape as W\n",
        "        learning_rate : Learning rate. Defaults to 1e-3.\n",
        "    Returns:\n",
        "        new_W: Updated weight matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Apply a gradient descent step on weight W using the gradient dW and the specified learning rate.\n",
        "    new_W = W - learning_rate * dW\n",
        "\n",
        "    return new_W\n",
        "\n",
        "def trainNetwork(model, data, **kwargs):\n",
        "    \"\"\"\n",
        "     Required arguments:\n",
        "    - model: Image classifier\n",
        "    - data: A dictionary of training and validation data containing:\n",
        "      'X_train': Array, shape (N_train, d_1, ..., d_k) of training images\n",
        "      'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images\n",
        "      'y_train': Array, shape (N_train,) of labels for training images\n",
        "      'y_val': Array, shape (N_val,) of labels for validation images\n",
        "\n",
        "    Optional arguments:\n",
        "    - learning_rate: A scalar for initial learning rate.\n",
        "    - lr_decay: A scalar for learning rate decay; after each epoch the\n",
        "      learning rate is multiplied by this value.\n",
        "    - batch_size: Size of minibatches used to compute loss and gradient\n",
        "      during training.\n",
        "    - num_epochs: The number of epochs to run for during training.\n",
        "    - print_every: Integer; training losses will be printed every\n",
        "      print_every iterations.\n",
        "    - verbose: Boolean; if set to false then no output will be printed\n",
        "      during training.\n",
        "    - num_train_samples: Number of training samples used to check training\n",
        "      accuracy; default is 1000; set to None to use entire training set.\n",
        "    - num_val_samples: Number of validation samples to use to check val\n",
        "      accuracy; default is None, which uses the entire validation set.\n",
        "    - optimizer: Choice of using either 'SGD' or 'SGD_Momentum' for updating weights; default is SGD.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    learning_rate =  kwargs.pop('learning_rate', 1e-3)\n",
        "    lr_decay = kwargs.pop('lr_decay', 1.0)\n",
        "    batch_size = kwargs.pop('batch_size', 100)\n",
        "    num_epochs = kwargs.pop('num_epochs', 10)\n",
        "    num_train_samples = kwargs.pop('num_train_samples', 1000)\n",
        "    num_val_samples = kwargs.pop('num_val_samples', None)\n",
        "    print_every = kwargs.pop('print_every', 10)   \n",
        "    verbose = kwargs.pop('verbose', True)\n",
        "    optimizer = kwargs.pop('optimizer', 'SGD')\n",
        "    \n",
        "    epoch = 0\n",
        "    best_val_acc = 0\n",
        "    best_params = {}\n",
        "    loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    \n",
        "    \n",
        "    num_train = data['X_train'].shape[0]\n",
        "    iterations_per_epoch = max(num_train // batch_size, 1)\n",
        "    num_iterations = num_epochs * iterations_per_epoch\n",
        "    \n",
        "    #Initialize velocity dictionary if optimizer is SGD_Momentum\n",
        "    if optimizer == 'SGD_Momentum':\n",
        "      velocity_dict = {p:np.zeros(w.shape) for p,w in model.params.items()}\n",
        "      \n",
        "    for t in range(num_iterations):\n",
        "        # Make a minibatch of training data\n",
        "        batch_mask = np.random.choice(num_train, batch_size)\n",
        "        X_batch = data['X_train'][batch_mask]\n",
        "        y_batch = data['y_train'][batch_mask]\n",
        "        \n",
        "        # Compute loss and gradient\n",
        "        loss, grads = model.forwards_backwards(X_batch, y_batch)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        if optimizer == 'SGD':\n",
        "          for p, w in model.params.items():\n",
        "              model.params[p] = SGD(w,grads[p], learning_rate=learning_rate)\n",
        "\n",
        "        elif optimizer == 'SGD_Momentum':\n",
        "          for p, w in model.params.items():\n",
        "              model.params[p], velocity_dict[p] = SGD_Momentum(w, grads[p], velocity_dict[p], beta=0.5, learning_rate=learning_rate)\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "        # Print training loss\n",
        "        if verbose and t % print_every == 0:\n",
        "            print('(Iteration %d / %d) loss: %f' % (\n",
        "                   t + 1, num_iterations, loss_history[-1]))\n",
        "         \n",
        "        # At the end of every epoch, increment the epoch counter and decay\n",
        "        # the learning rate.\n",
        "        epoch_end = (t + 1) % iterations_per_epoch == 0\n",
        "        if epoch_end:\n",
        "            epoch += 1\n",
        "            learning_rate *= lr_decay\n",
        "        \n",
        "        # Check train and val accuracy on the first iteration, the last\n",
        "        # iteration, and at the end of each epoch.\n",
        "        first_it = (t == 0)\n",
        "        last_it = (t == num_iterations - 1)\n",
        "        if first_it or last_it or epoch_end:\n",
        "            train_acc = testNetwork(model, data['X_train'], data['y_train'],\n",
        "                num_samples= num_train_samples)\n",
        "            val_acc = testNetwork(model, data['X_val'], data['y_val'],\n",
        "                num_samples=num_val_samples)\n",
        "            train_acc_history.append(train_acc)\n",
        "            val_acc_history.append(val_acc)\n",
        "\n",
        "            if verbose:\n",
        "                print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
        "                       epoch, num_epochs, train_acc, val_acc))\n",
        "\n",
        "            # Keep track of the best model\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_params = {}\n",
        "                for k, v in model.params.items():\n",
        "                    best_params[k] = v.copy()\n",
        "        \n",
        "    model.params = best_params\n",
        "        \n",
        "    return model, train_acc_history, val_acc_history\n",
        "        \n",
        "\n",
        "# load data\n",
        "data = load_cifar10() \n",
        "train_data = { k: data[k] for k in ['X_train', 'y_train', \n",
        "                                    'X_val', 'y_val']}\n",
        "\n",
        "# initialize model\n",
        "model_SGD = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
        "\n",
        "# start training using SGD\n",
        "model_SGD, train_acc_history_SGD, val_acc_history_SGD = trainNetwork(\n",
        "    model_SGD, train_data, learning_rate = 1e-2,\n",
        "    lr_decay= 1.0, num_epochs=10, \n",
        "    batch_size= 100, print_every=1000, optimizer = 'SGD')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 4000) loss: 2.296600\n",
            "(Epoch 0 / 10) train acc: 0.113000; val_acc: 0.120600\n",
            "(Epoch 1 / 10) train acc: 0.369000; val_acc: 0.360000\n",
            "(Epoch 2 / 10) train acc: 0.441000; val_acc: 0.407200\n",
            "(Iteration 1001 / 4000) loss: 1.842522\n",
            "(Epoch 3 / 10) train acc: 0.454000; val_acc: 0.428600\n",
            "(Epoch 4 / 10) train acc: 0.475000; val_acc: 0.451100\n",
            "(Epoch 5 / 10) train acc: 0.474000; val_acc: 0.463100\n",
            "(Iteration 2001 / 4000) loss: 1.347762\n",
            "(Epoch 6 / 10) train acc: 0.525000; val_acc: 0.474300\n",
            "(Epoch 7 / 10) train acc: 0.562000; val_acc: 0.476600\n",
            "(Iteration 3001 / 4000) loss: 1.344899\n",
            "(Epoch 8 / 10) train acc: 0.563000; val_acc: 0.487500\n",
            "(Epoch 9 / 10) train acc: 0.553000; val_acc: 0.492800\n",
            "(Epoch 10 / 10) train acc: 0.573000; val_acc: 0.501100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2ilTVXIw_7q"
      },
      "source": [
        "# Training with SGD_Momentum\n",
        "\n",
        "The model above was trained using SGD. Now we implement the SGD_Momentum function to train the model using SGD with momentum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jGVPZOXtV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8691c3a5-da80-47c4-fdd5-607d4b6ced41"
      },
      "source": [
        "def SGD_Momentum(W, dW, velocity, beta=0.5, learning_rate=1e-3):\n",
        "    \"\"\" Apply a gradient descent with momentum update on weight W\n",
        "    Inputs:\n",
        "        W : Weight matrix\n",
        "        dW : gradient of weight, same shape as W\n",
        "        velocity : velocity matrix, same shape as W\n",
        "        beta : scalar value in range [0,1] weighting the velocity matrix. Setting it to 0 should make SGD_Momentum same as SGD. \n",
        "               Defaults to 0.5.\n",
        "        learning_rate : Learning rate. Defaults to 1e-3.\n",
        "    Returns:\n",
        "        new_W: Updated weight matrix\n",
        "        new_velocity: Updated velocity matrix\n",
        "    \"\"\"\n",
        "    new_velocity = dW + (beta * velocity)\n",
        "    new_W = W - (learning_rate * new_velocity)\n",
        "    return new_W, new_velocity\n",
        "\n",
        "# initialize model\n",
        "model_SGD_Momentum = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
        "\n",
        "# start training \n",
        "#Using SGD_Momentum as optimizer for trainning for training\n",
        "model_SGD_Momentum, train_acc_history_SGD_Momentum, val_acc_history_SGD_Momentum = trainNetwork(\n",
        "    model_SGD_Momentum, train_data, learning_rate = 1e-2,\n",
        "    lr_decay=1.0, num_epochs=10, \n",
        "    batch_size=100, print_every=1000, optimizer = 'SGD_Momentum')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 4000) loss: 2.303177\n",
            "(Epoch 0 / 10) train acc: 0.098000; val_acc: 0.098900\n",
            "(Epoch 1 / 10) train acc: 0.413000; val_acc: 0.408400\n",
            "(Epoch 2 / 10) train acc: 0.472000; val_acc: 0.449900\n",
            "(Iteration 1001 / 4000) loss: 1.450418\n",
            "(Epoch 3 / 10) train acc: 0.500000; val_acc: 0.470400\n",
            "(Epoch 4 / 10) train acc: 0.519000; val_acc: 0.485900\n",
            "(Epoch 5 / 10) train acc: 0.538000; val_acc: 0.489000\n",
            "(Iteration 2001 / 4000) loss: 1.178795\n",
            "(Epoch 6 / 10) train acc: 0.579000; val_acc: 0.500100\n",
            "(Epoch 7 / 10) train acc: 0.587000; val_acc: 0.498500\n",
            "(Iteration 3001 / 4000) loss: 1.085630\n",
            "(Epoch 8 / 10) train acc: 0.635000; val_acc: 0.508000\n",
            "(Epoch 9 / 10) train acc: 0.609000; val_acc: 0.511200\n",
            "(Epoch 10 / 10) train acc: 0.656000; val_acc: 0.521200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcovGmpXvXXa"
      },
      "source": [
        "# Report Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwCq8pBhu6dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "9e27b4a8-3c71-488a-bd2e-30edc618ce13"
      },
      "source": [
        "# report test accuracy\n",
        "acc = testNetwork(model_SGD, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy of model_SGD: {}\".format(acc))\n",
        "# report test accuracy\n",
        "acc = testNetwork(model_SGD_Momentum, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy of model_SGD_Momentum: {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy of model_SGD: 0.4991\n",
            "Test accuracy of model_SGD_Momentum: 0.5051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTrmbULS7i2N"
      },
      "source": [
        "#Plot\n",
        "\n",
        "Using the train_acc_history and val_acc_history, plot the train & val accuracy versus epochs on one plot, using SGD and SGD_Momentum as optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPjtnbya9S7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "20eea43d-45f5-40cc-a154-943757baeb2a"
      },
      "source": [
        "plt.plot(train_acc_history_SGD, label=\"Training Accuracy (No Momentum)\")\n",
        "plt.plot(train_acc_history_SGD_Momentum, label=\"Training Accuracy With Momentum\")\n",
        "plt.plot(val_acc_history_SGD, label=\"Validation Accuracy (No Momentum)\")\n",
        "plt.plot(val_acc_history_SGD_Momentum, label=\"Validation Accuracy With Momentum\")\n",
        "plt.legend()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff4630e0ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVyVVeLH8c9zN7bLDgKyCLiDCAruS2qLVubSMrZMaU2aTY0t0zY1zTjN/BqnmTGraZr2fbSx0qxM27RyBwRXRBRRQHYQuVwu3OX8/njwCgiKCVzE8369eN377OeCfjmc5zznKEIIJEmSpIufxtUFkCRJkjqGDHRJkqQeQga6JElSDyEDXZIkqYeQgS5JktRD6Fx14aCgIBEdHe2qy0uSJF2U0tPTy4UQwa1tc1mgR0dHk5aW5qrLS5IkXZQURTna1jbZ5CJJktRDyECXJEnqIWSgS5Ik9RAy0CVJknoIGeiSJEk9hAx0SZKkHkIGuiRJUg8hA12SJKmrWKrh28VQldcpp3fZg0WSJEmXDFsDpL0JPzwHdZXgGwEj7u7wy8hAlyRJ6ixCwL5P4btn1Fp5zGVw5TPQO6lTLicDXZIkqTPkbYKvn4bjO6FXPPzyE+h7OShKp11SBrokSVJHKs1S28kPrgOfcJj1CgydAxptp19aBrokSVJHOFkEG5+FjA/AYIQrFsOohaD36LIiyECXJEm6EJaTsOVF2PIvcNjUEJ/wCHgFdnlRZKBLkuQ6DofaptyJ7cqdxm6F9Hdg4xIwl8OQG2DK0xAQ47IiyUCXJKnrWS2w/RX46Xlw84aB02DA1RAzAXRuri7d2QkBWWvg2z9B5WHoMx6uegbCk11dMhnokiR1ISFg7ydqGFYfg/5XgdYAmf+F1DfUtue+k2HgNeo2ryBXl7i5Y9vUnisFOyB4ENz6P7Wc3eQvDBnokiR1jWPbYP2TUJgOoQkwcw3EXqZus1rgyI9w8CvIXgdZnwMKRI6EgVertffgga4LzvIctefKgS/AGAozXoLEW0HbvSJUEUK45MIpKSlCTkEnSZeAylz45o9qM4V3mNrOnHhz2934hICiXZD9lRrwRbvU9f4xargPvBqixoBW3/llN5WqbeTp74DeE8Y/AKN/DQavzr92GxRFSRdCpLS6TQa6JEmdoq4Kfvg77HhNbVYZ9wCMvf/8w7C6UO3Tnf2VWou314O7L/S7Ug33fleAh1/Hlr3eBFtfhs0vqNdLuQsmPgbGVudm7lIy0CVJ6jq2BrU9/Ie/qYNRDfslTPk9eIde+LnrTZC7QW2WObhO7V2i0ak19oHXqDdXA2J//vntNsh4Hzb+FUwlEDcTLv8jBPa98LJ3EBnokiR1PiHUtu9v/6g2s8ROhqv+AqFDOud6DrvaHp/9lfpVlqWuDx4EA6apAR+R0r4nNIVQz/HtH6H8IESOhqv+rLbhdzMy0CVJ6lyF6bD+93BsixqoV/1FbQrpypuYlUdON80c3aw+5OMZqIb7gGnQdwq4Gc88riBN7blybAsE9ocr/6T+MugmPVdakoEuSVLnOJEP3/0J9qwEr2CY/CQMu8P1vT/qTsChb9WAz/labfrRGiBmYmOvmWlgq1dHQdy/Grx6weTfdY+yn4MMdEmSOpblJGxaClv/rdZkx9wH4x4Edx9Xl+xMdqvaZfLgOsheqzYHASga0HnA2N+oX63V3ruhswV6u34VKYoyDXgB0AJvCCGWtLLPL4DFgAB2CSFu/dklliSpe7LbYOc7sOGv6g3JoXPUboh+ka4uWdu0evUJ1JgJalNQeY4a7JZqGHVPx9ys7SbOGeiKomiBl4ErgQIgVVGUNUKI/U326Q/8DhgnhKhSFKVXZxVYkiQXEEJtuvj6aSjPhj7j4KqVED7c1SU7P4oCwQPUrx6oPTX0kcAhIUQugKIoK4CZwP4m+8wHXhZCVAEIIUo7uqCSJLlI8R5Y/xQc+QEC+sKcD2HQtd32puGlrD2BHg7kN1kuAEa12GcAgKIom1GbZRYLIda1PJGiKAuABQBRUVE/p7ySJHWVk0Ww4S+Q8aH64M60v6kP2OgMri6Z1IaOup2rA/oDk4AI4EdFURKEECea7iSEeA14DdSboh10bUmSOlJDLWx5qfEpSat6w3PiI+Dh7+qSSefQnkAvBJre8YhoXNdUAbBdCGEFjiiKchA14FM7pJSSJHU+h10d9fD7v4CpGOJmqbPuuHB8b+n8tCfQU4H+iqLEoAb5zUDLHiyrgVuAtxVFCUJtgsntyIJKktRJHA61ffzrp6FkD0SMgF+8B1EtW1al7u6cgS6EsCmKcj+wHrV9/C0hxD5FUZ4B0oQQaxq3XaUoyn7ADjwqhKjozIJLknQWQkD9SXW0QFNJ49ep92XN19WWgbCDXxTc+BbEXy9veF6k5INFknQxsda1COfSFu+bvNrrzzxeo1OfijT2AmPI6deAGBhyI+jdu/4zSeflgh8skiSpC1QXQMn+M2vUtWWnl+tPtnKgoo5ZciqgA/s1BnWL0DaGgLsfaDRd/tGkriEDXZJcrWQ/bHpenZpN2E+vd/M9HcahQ1uEdJOg9gzq9uOPSF1D/iuQJFcpTIeflqrTmum9YMyvYfDM08Gt93B1CaVOUFZTj5teg497x8+4JANdkrqSEJD3E/z0T8jdqDaBXPaEOqaIZ4CrSyd1MCEEh8tMpOVVkZpXRfrRSvIqzPz1+gRuGdnxD1fKQJekriCEOtrfT/+EglS1qeTKP0PKneDm7erSSR2k3mZnb2E1qXlVpDUGeJXZCkCAl4GUPv7cOiqKUTGd88tbBrokdSaHHfatUtvIS/aqXQOvXQpJt8keJT3ACXMD6UerSDtaRVpeJbsKqmmwOQCIDfLiisEhjIgOICXan5ggL5RO7g4qA12SOoOtHnatgM3L1PG3gwbC7FdhyA1dM1v9ebDaHRwoqqHB7sAhBHaHwOEQ2E+9FwK7gybvT7822y4aj2u63bmuyfZm+4G/p57efh709vMg3M+DEF833HTtmDauiwkhyK+sI+1oZWMNvJKcUhMAeq3CkHBf5o7pQ0p0AMl9/AkyunV5GWWgS1JHaqiFne/B5heh5jiEJcGcD2Dgtd2uu2CFqZ7lO47x/rajlJxspc96J1AU0CoKGo2ivipQ22A/Y79gb7fGgHent68HYafeNwZ/oJeh02u7NruDrKIaUvMqSTtaSVpeFaU16vfJ211Hch9/Zg0LJ7mPP4kRfngYXP9LSAa6JHWEuhOQ+jpsewXMFdBnPMx6WZ0ouZs9dbm3sJp3t+Tx2a7jNNgcTOgfxJPXDMbXQ4/2VNBqFLQaBY2iNFlH8+2N2zRNtzdZp1HOXN9aCFusdoqqLRw/Udf41fi+uo4DxTV8f6AUi9XR7BiDTkNv39MBfyr8w3xPLbvjaTi/eDPV28g4dvrmZcaxE5gbf9mE+3kwtm8gKY3NJwN6eaPRdK+fK8hAl6QLYyqFbf+GHW9AQw30nwoTHoao0a4uWTM2u4Ov95fwzuY8duRV4qHX8ouUCOaOiaZ/iGtvyrrrtcQEeRET5NXqdiEEJ8xWCp2BX0dRtcW5vCmnnNIaC44WD72fasoJ821eu+/d+F4ISD9aRfrRKlLzKskqOolDgEaBwWE+/CIlkuQ+/qRE+xPme3F0IZWBLkk/x4l8dYjZne+q7eXxs2H8QxA21NUla6aqtoEVqfm8vzWP49UWIvw9+P21g7kpORJfz+7Vlt8WRVHw9zLg72VgSLhvq/tY7Q5KTlqctfvCE3UUVau1/YIqM9uPVFBjsbV6rIdey/A+ftw/pT8jov0ZFuWP0e3ijMaLs9SS5CrlObBpGexeoS4n3gzjHoKgfq4tVwsHik/yzuY8VmUUUm9zMLZvIItnxHP54BC03bCp4ELptRoi/D2J8Pdsc58ai7VZzd5mFwyL8mNwmA96bfe6v/FzyUCXpPYo2qU+1bn/M9C5w4i7Ycz93WpyZLtD8G2W2qyyNbcCd72G64eHM3dsNINCfVxdPJfzdtfj7a5ngIubmDqTDHRJOptj2+DHf8Chb8DNR20fH3UvGINdXTKnarOVj9KO8d7WoxRU1dHb150nrh7EnJRI/L3kdHGXEhnoktSSEHD4O7VGfnSzOpLhlKfVWrmHn6tL55RTUsM7W/L4dGchdVY7I2MCeOqawVwZF4KuhzQhSOdHBrokAZgroSBNfSz/4Doo3g0+4erEyMPvAEPbbbNdyeEQfH+glHe25LHpUDkGnYZZSb2ZOzaa+N6t3zCULh0y0KVLj8MOpfshf0djiO+AikPqNkWjDlU74yUYenO3meH+pMXKyrQC3tuax9EKM6E+7jw6dSA3j4gk0AVPJErdkwx0qeerLVdr3gWpaogX7gRrrbrNMwgiR6pjq0SMgN7DwM3o2vI2cbjMxLtb8vg4vQBzg52UPv48OnUgU+NDe0zPDKnjyECXeha7TR0E61SAF6SqY6mAOv1ayBAY1hjeESPAP7rbPcnpcAh+yCnjnc15/HCwDINWw/TEMO4cG0NChGxWkdomA126uJlKT9e8C9Lg+E6wmtVtxhA1tIfPVWvhYUndpi28NaZ6G5+kF/Duljxyy2sJ9nbj4SsHcMvIKIK9ZbOKdG4y0KWLh90KxXuaN5+cOKpu0+jVpzSH33G69u0X1e1q361xOAT/S8vnufXZVNY2kBTpxws3J3H1kDAMOtmsIrWfDHSp+6opbqx5n6p9Z4DNom7zDlNDe+R89TUs8aKcsi0z/wR//GwvuwqqSenjz+t3pJDcx9/VxZI6gKO2FmtxMdbjRViLjmMtKsJ2vAhrcTEBc+fiPWVyh19TBrrUPdga1K6CzuaTVKjOV7dpDWpgp/wKIlLU5hPfCNeW9wJVmOp5bl02H6XlE+ztxvNzEpmVFN7pQ8JKHUPYbNjKyrAWFTkD21ZUhLWoWF1XVISjurr5QRoNul690IeFgXC0fuILJANdco3qwuZNJ0W7wN44JrdPBESOgNH3QsRItSlF1zPakG12Bx9uP8Y/v87G3GBn/oQYFl3eH+9OmDBY+nmEEDhOnmwe1s6atvplKy0Fe/Nx3DU+PujDwtCHheExLAl9WG91ube6TterF4qucyNXBrrU+awWtfbdtPnkZKG6TeumdhUcOV+teUeMAJ/eri1vJ9lxpJI/fLaXA8U1jOsXyOLr4l0+dO2lQDgciPp6HBYLwmLBUWdB1FuwV5/EWlyk1qybhnVREQ6zuflJ9Hr0oaHoQ0PxGjkCXViYGti9w9CHhqILC0NrdH13VxnoUscSAqoLTgd3/g41zO0N6nbfKHWs8IjG8A5N6DYP73SWkpMW/ro2i9WZx+nt686/bxvO1UNCZfMKajuz3WRC1NXhqK9XXy31OCx1COer5XQYWyyIOguO+sbXpuvbeq0/92xM2sBA9KGhuMXG4DVubGPtOlStWYeFoQsKQulmM061pl2BrijKNOAFQAu8IYRY0mL7PODvQGO1i38JId7owHJK3ZW1Do5nNjaf7ID8VDAVq9t0Hmrte/S9p3ueeIe6trxdqMHm4J0tR3jh2xysdsFvpvTj3kl9z3smnYuV3WRSa7/FJdhKitX25ZJibMUlas24uASHyXR+J9Vo0Li7o7i7N3/18EDj5YU2KAiNmxuKhzsaN/fWXxuP0xqNamCHhqJx7xkTdp/zX5aiKFrgZeBKoABIVRRljRBif4tdPxJC3N8JZZS6CyHUboKnat4FO9RuhI7GiQP8oyFmohrckSPUh3i62YTIXeWnnDIWr9nH4bJapgzqxR+mxxHdxow8FxshBI6aGqzFxdhKStRmiuISNayLirGWlGArLsZRW9v8QEVBFxSELjQUt5gYvEaPQR8agsbHp/WQbvGqcXcHvV7+ZXMW7akqjAQOCSFyARRFWQHMBFoGutTT2G2NNy23nQ7x2lJ1m94TwpNh7G8am09SwNjLteXtBgqqzPzfl1l8tbeYqABP3pybwuWDQ856jHA41B4TBQU4LBYUnR5Fp1VvoOl0zZbVdXoUvQ5F27iPXq9u64AmAecNweISbMVNatdNl4uLz2xjVhR0wcFqWMfGqs0WIaHoQkPUG4MhIeiCg1EMPbt5rSmz1UxZXRnldeXqq7ncuTyz70xGho3s8Gu2J9DDgfwmywXAqFb2u0FRlInAQeAhIUR+K/tI3Z3dCkd+VCdyOPAlmMvV9QF9oe8UteYdMQJ6xYP20mg6aA+L1c7rP+by8kZ1kK/fXjmA+RNjcddrEUJgP3ECa0Eh1sICrAUFNBQUqMsFBViPH0c0NFx4IRSlecDr1NBHf+qXQuvLil6HsDuwlZZiLSlBtAxrjaYxrENw69cP44Tx6EJC0YeGoAsNU1+Dg1H0Pf+vMYdwcKL+BOV15c6ALqsro6KuQn1vVgO7vK4cs818xvE6RUegRyCjwzpnztmO+h/5ObBcCFGvKMo9wLvAlJY7KYqyAFgAEBUV1UGXli6YrR4Ob4CsNWqIW06AwQgDpsLg6yB6IngFurqU3dZ3WSX89dMMGgoLuStYcFO4Fs8duyhbVYA1Xw3wls0PWl9f9BERuA0ciPHyKRgiItBHRKDx8kJYbQibFWw2hM2GsNnPvmy1Iezqe5zLTfaxNu5nt525bLXhMNeBoqhlmTgRXWgo+rBQdCEhag+O4OBO727nala7lQpLBWXmMmctumnN+tT7iroKbOLMuUk9dZ4EewYT5BHE4MDBBHuo74M8gtT3nuqrr5svGqXzbq6256dUCDSdZyuC0zc/ARBCVDRZfAN4rrUTCSFeA14DSElJEa3tI3WRBjMc+lYN8ex16oz1br4w6BoYPEOtjet7xo2ijiCsVvWpv/x8Z+36xOE88rMO41FRwkv1p2/uWYB6d3f0EeEYwiPwTElBHxGBIVINbX14OFpv2V2xowkhqLfXU9NQQ01DDScbTmKympot1zTUYGpQ152oP+EM7xP1J1o9Z4B7gDOYY/1iCfYIJtgzmECPQPV9Y3B76rvHGEHtCfRUoL+iKDGoQX4zcGvTHRRFCRNCFDUuzgCyOrSUUseor4Gcr9XmlJxv1EGsPAIgfhbEzVJvaPbgLoRCCITV2qw7W/MubvVq/2STCevx46ebRAoKsBYXg+P0030OjYYSD3/KvQLoNWIcAcMH4R4ViSEiHH1EBNrAQHnz7jwJIaiz1TmD1/llrWm+3PKryXarw3rWa+g0OnwMPngbvPEx+BDpHcnwXsMJ8jxdmz4V0gEeAeg1F1cz0jkDXQhhUxTlfmA9arfFt4QQ+xRFeQZIE0KsARYpijIDsAGVwLxOLLN0PupOqDPw7F+j1sjt9eoohIm3QNwM6DO+27WFC5uNhrw8bKWlZ4TtqYdCHJYWYdwynNtYbhrK56ILDkYfEYFHcjI+EeHow8PJsHry/F4T+6zuzEyO4omrBxHiI/+SOZd6ez3HTccpNBVy3HScAlMBx03HOW46TpWlihqrWnO2C/tZz+OudcdoMOJt8Mbb4I2vuy+R3pHN1p0KbKPe2GzZ2+CNm9atR/+iVYRwTctHSkqKSEtLc8m1e7zaCsj+Ug3x3I3gsKrTqQ2eoYZ45CjQaF1dSgBslZXUZ2djyc6mPvsgluwDNBw6fO6bhFrt6S5tbm4turi5obi5o/FwR3FzR3F3a94X2d2tebc4t+bLGg+PM/om55TUsPjzfWw+VMGgUG+emTmEkTEBnfzduXhY7VaKaosoNBW2GtpldWXN9tdpdPT26k1vY28CPQIx6o3Ngtfb4I233rv5ssEbg7bn/gXZXoqipAshUlrb1r2qZtLPZyqFrM/V5pS8TSDs4NcHRi9Um1N6DwcXPukmGhqoP3LkdHgfyMZyMBt7WblzH21wEO4DBuJ1+xjcBw5E37s3iruHGtBNA9vNrct6VNRYrLz4XQ5vb87D06DlmZnx3Doy6pKbhNnmsFFiLlGDuqaA47XHKawpdAZ4qbkUwenKoVbREuoVSrgxnPHh4+lt7E24MZxwYzi9jb3p5dmrU28OXqpkoF/MqgvVEM9aA0e3AAIC+8H4ByFupjo3Zhf/eSmEwFZWRn32QeoPZmM5kE19djb1ublgU3sHKHo9hv79MI6fgNvAAbgPHIjbgAHoArtPTxohBKszC3l27QHKTfXMSYnk0akDe+z8nXaHnbK6sjNq16eWi2uLmzWHKCiEeIUQbgxnVNioZoEdbgynl2cvdBoZL11NfscvNlV5alNK1hr1oR+AXnEw6Qm1SaXX4C4LcUd9PfWHDqnhnX0AS/ZB6rOzsVdVOffRhYbiPnAgxkmTnOFtiI4+aze4GouV9KNVlJy0oFEUtBr169T70+s4/V5R0LTYT11H8+2nztF0e4t1R8pr+dPn+0jNqyIxwpfX70ghKdKvU7+XQggqLBWcbDiJ1W6lwd5Ag6OBBnsDVodVXde47FzfZJ3VYW322nIf5/o29qmz1Z3RHa+XRy96G3uTGJzINTHXqGHtHU64VzihXqHoL9GngLszGegXg5oSyPxAbU4p2qWuC0uEy/8Ag2dCUL9OvbwQAltxsbOppP5gNpbsgzTk5TmHEFXc3XEbMADvKy7HbcBANbwHDEDrd+4grDZb2ZFXyfbcCnbkVbK3sBqHizu1BngZ+NsNCdyUHIlG0zG/IE0NJgpNhRSYCiioKXA2VxTUqLVhi93ys89t0BjQa/XNXg1a9Uuv0aPX6PHQeeDr5uvcR6/Rq/toDHjqPQnzCnPWsMOMYbhpe+ZfIz2ZDPTubs/H8OVv1Yd9IkbAlX9Wb2z6R3faJe0mE3UZGZjT0qnbuRNLdjaOkyed2/Xh4bgNGoTP1Kuc4W2IilKfQmyHclM9O45UsuNIJdtyK8guqUEIMOg0JEX6cf/kfoyMCSQ6yBMhwO4Q2IXA0fhqdwgcDk6/d64TLdbRfHvja7Ptp87bZLubTsPsYRH4ep5fDfTUjcHWArvQVHhGX2ej3kiEdwQxvjGMDx9PuDEcf3f/VgPXoG2yrklYGzQGdBpdj+65IbWfDPTuylypBvm+T9Ugn/lvCB7QKZeylZdjTkvHnJ6OOT2N+gPZavc+rRb3uDh8rrlabeceOBC3/v3P+6GY4moL249UsL0xxA+Vqg/heOi1JPfx55qEMEbFBJAY6Ye7vnv0vmmNEILyuvIzatmnXkvMJTiazESj0+icNd64wDgivCMIN4YTYYwgwjsCH4OPDGKpQ8lA745yvoHP7gdzBUx5GsY92GF9xYUQWAsKGgM8jbq0dLXpBLXZxCMxkaCFC/FMScYjMRGN1/mNECiEoKCqju1HTjehHK1Qx7QwuulIifbnhuERjIwJICHct9tNgmy2msmvyW81sFtrFunl0Ytw73CSQ5LPCOxgj2C03aR7qHRpkIHendSb4OvfQ/rb6o3O21aq069dAOFwUJ+Tgzktjbr0dMxp6er0WYDG1xfP4cPxu+lGPJOTcY+LO+/R8IQQHCmvdda+t+dWcLxaDT0/Tz0jogO4fXQfRsUEMjjMu1t096uurya/Jp9jJ4+przXHnMsVlopm+55qFon1jWVC+ATCvdXADvcOp7dXb9x18qEiqfuQgd5dHN0KqxdC1VEY9wBMfupnzaMpGhqo27fPGd7mjAznZLW6kBA8R4xQa9/Jybj163feQ646HIKcUhM7jlSwrTHEy2rUGWGCjAZGxQRyT0wAo2IDGNDLu8NuKJ6PUz1Gzgjtk+rryYaTzfYP8Qwh0juSyyIvI9I7kkjvSCK8I4gwymYR6eIiA93VbPWw4f9g84vgFwV3roU+Y9t9uKO2FnNmpjPA63bvVh9xBwwxMfhcdSUeycnqAFHh5z+rvN0hyCo62VgDr2DHkUqqzOp4GaE+7oztG8iomEBGxQYQG+TVZeHnEA5KzaWt1rLza/KbDV2qUTSEeYUR5R3F1TFXO0M7yjuKCO8IWcuWegwZ6K5UtBtW3QOl+yF5Hlz1F3A7+w1HW1XV6dp3WhqWrCy166BGg/vgwfjP+YUa4MnJ5/WgjrnBxpHyWnLLahtfTeSW13K41ERtg9o1MTLAg8sHhzAqJoBRMYFEBnh0aoDbHDaKTEXOwD5Vy86vUb8aHKeHB9BpdEQYI4jyiSIlNMUZ2FE+UfT26i37TEuXBBnormC3weZlsHEJeAbCrSthwFWt7iqEwLx9OyfXfoU5PZ2Gw4cBUAwGPBITCVwwH8/kFDySktAaz34D0+4QHD9RR+6pwC6rJbfcxJGyWme79ynhfh7EBntxY3IEw6L8GRkTQG8/j475/G0wW82kl6SzvWg7O4p3kFOV0+xhF3etO5E+kfTx6cOEiAlqaPtEEekdSahnqLwBKV3yZKB3tYrDaq28IBXir4dr/wmeZw7yJITAtHEjFf95lbpdu9B4e+MxfBi+M2fimZKM+5AhaNq4gVlttnK4vDGwy0yna94VtTTYTner83bXERtsZHRsILHBXsQEGRtfvbqk+6DVbmV3+W62F21ne9F2dpfvxuawodfoSeqVxLwh84jyjnIGd7BHsGzPlqSzkIHeVYSA1Dfg66fVm503vAkJN565m8NBzdffUP7qq9RnZaHv3ZvQxX/Ed/ZsNG6nb5I22BwcK63hcNMmkrJacstrqaxt2hShEBXoSWyQkcsGBhMb5EVssBrcgV6GLg1Ih3BwsOog24u2s7VoKztLdlJnq0NBIS4wjjvi7mBU2CiG9RqGh65z/xqQpJ5IBnpXqC6Ez+6D3A3Q93KY+S/w6d1sF2GzcfLLLyl/9TUacnMxREcT9te/4jv9WsosdpZnFjercedX1WFv8nx8sLcbMUFeTI0PIbZJTTsywBO9i7oKCiHIr8lnW9E2thdtJ7U4lap6dZyXGN8YZvadyeiw0aSEpuDr5uuSMkpSTyIDvTMJAXtWwpePqGOST38eku9sNniWo6GB6lWrqXjjDaz5+bgNGED40n/iPXUqilZLxrEq5r+XTrmpHne9hpggI/HhvsxI7E1MsBexQUZigr3wce8eN/3KzGVsL97ubEYpqlUnsgrxDGFCxARGh41mZOhIQrxCXFxSSep5ZKB3ltoK+OJBdVTEyFEw6xUI7Ovc7Kir48TKj6l4801sJSW4JyQQ8rsnME6a5Owb/llmIY9+vG+khLUAACAASURBVJtQH3e++M144sJ8XNKv+2xqGmpILU51BvjhavWmrY/Bh5GhI7lryF2MDhtNH58+sv1bkjqZDPTOkP0VrFmkDqh1xZ9g7G+cMwTZTSaqli+n8u13sFdW4pmSQtiz/4fX2LHOwHM4BMu+y+HF73IYGR3Af25PJsCre8zUUm+vJ6M0wxng+yr24RAO3LXuDA8Zzox+MxgVNopB/oNkrxNJ6mIy0DuS5SSsfxIy3oeQIXD7KggdAoD9xAkq3/+Ayg8+wFFdjdf48QQtvAfPlOYzSdU12Hnk4118ubuIm5Ij+L/ZCS4d78TmsLG/Yr8zwDNKM2hwNKBVtCQEJTA/YT6jwkaRGJwopweTJBeTgd5R8jbB6nuhugDGP6xOOKFzw1ZeTuW771L14X9xmM0YL7+coIX34JGQcMYpSk5amP9eGnsKq3nymkHMnxDb5c0UNoeN7Mps0krSSC1OZWfJTmqsNQAM8B/AnEFzGB02muSQZLz05zdwlyRJnUsG+oWyWuD7P8PWl9Uxyu9cB1GjsBYXU/HmW5z43/8QDQ34XH01gffcg/vA1ofA3VtYzd3vpnHSYuW121O4Mq5rbhraHDYOVB4grTiN1BI1wE1WdXjbaJ9oroq+itFhoxkROoJAj+4zRZwkSWeSgX4hjmfAqoVQdgBG3A1XPkNDSSUVT/+BE6tXgxD4XncdgfPn4xYb0+Zp1u0t4sGPMgnwNPDxwrHE9fbptCLbHDayKrJO18BLd1JrrQXUAL865mpGhI4gJSSFYM/gTiuHJEkdTwb6z2G3wk9L4cfnwCsYfvkJ9UoMFU8/Q/UXX6JoNPjdeAOBv7obQ0R4m6cRQvDvjYf5+/pshkX58ertyfTy7tiBoqwOK1kVWaQWp5JWkkZGaYYzwGN8Y7g25lpGhI4gOSRZBrgkXeRkoJ+vsoPqo/vHd0LCL7D0vZvyl5ZT8/XXKO7uBNx+OwF33ok+pNdZT2Ox2vndp3tYlVHIzKTe/O2GoR3yuL3VYWV/xf7TAV6S4Rx5MNY3lumx00kJTSElJIUgj6ALvp4kSd2HDPTzkfYWrPsd6D2oS3yG8nVZmH6Yh8ZoJHDBAgLm3oEu4MxxWVoqq6nnnvfT2HnsBI9cNYD7Jvf72Tc/rQ4r+8r3kVaSRlpxGjtL1cfpAfr69uW6vtc5a+AywCWpZ5OB3l41xYjPH8KsG0n53l6Y3/4PWj8/gh9YhP9tt6H1aV+794Hik/zqnTQqauv5923DuSYh7LyKYbVb2Vexr1kTyqkA7+fXj5l9ZzoDXN7ElKRLiwz0dhI535P/YwC1RQVogy30euwx/Of84rzm3Pwuq4RFyzMwuuv43z1jGBrh167j8mvyWXdkHanFqWSWZTYL8Fn9ZpESkiIDXJKk9gW6oijTgBcALfCGEGJJG/vdAHwMjBBCpHVYKbsBy09rqC1yJ+CuOwletAiNe/tvXgoheOOnIzz7VRZDevvy+h0phPqe+/gqSxWv7n6Vj7I/wuaw0d+/P7P7zSYlVA3wAPdzN+9IknTpOGegK4qiBV4GrgQKgFRFUdYIIfa32M8beADY3hkFdSmHg9odOwEtgb/61XmFeYPNwdOr9/JRWj7XJITyz5uS8DCc/eanxWbhw6wPeWPPG5htZmb3m83CxIWEeoVe4AeRJKkna08NfSRwSAiRC6AoygpgJrC/xX5/Bv4GPNqhJewOSvZiOmbDLTr8vKZ1q6ptYOEH6Ww/UslvpvTjoSsGnHVwLYdw8EXuF7yU8RLFtcVcFnEZDw5/kH7+/TriU0iS1MO1J9DDgfwmywXAqKY7KIoyHIgUQnypKEqbga4oygJgAUBUVNT5l9ZF7HvXUVduIPCaKe0+5lCpiV+9m0pRtYUXbk5iZlLb/dEBthzfwtK0pWRXZRMXGMez459lROiICy26JEmXkAu+KaooigZYCsw7175CiNeA1wBSUlLEOXbvNswb14NQ8JoytV37/3iwjPv+uxM3nYbl80eT3Me/zX2zK7N5Pv15Nh/fTLgxnL9N+BvTYqahUVw3IJckSRen9gR6IRDZZDmicd0p3sAQYGNjX+pQYI2iKDN6xI3RBjOm3blo3Ix4Dks65+7vbsnjmS/207+XkTfmphDh79nqfsW1xfwr41+sObwGb4M3j6Q8wi2DbpEjFkqS9LO1J9BTgf6KosSgBvnNwK2nNgohqgHnEyuKomwEHukRYQ6Io5upPa7DM2kwShuTMgPY7A7+9Pl+3t92lCsG92LZzcMwup357TU1mHhr71u8v/997MLO3Pi53J1wt5yCTZKkC3bOQBdC2BRFuR9Yj9pt8S0hxD5FUZ4B0oQQazq7kK5k3fYF1lodAVdc2+Y+1XVW7vtwJ5sOlXPPxFgemzYIbYubn1aHlZXZK/nPrv9QVV/FNTHXsGj4IsKNZ29blyRJaq92taELIdYCa1us+0Mb+0668GJ1H6ZNPwFgvGxyq9vzymu5691U8ivNPHfDUH4xIrLZdiEE3x77lhd2vsDRk0cZGTqSh1MeJj4wvtPLLknSpUU+KXo2J4uozalC36sXhlZ65Ww9XMHCD9LRKPDBr0YxKrZ5l8bM0kz+mfZPMssy6evbl5cvf5kJ4RPk3JqSJHUKGehnIQ5+R22pAb/po8/YtmLHMX6/ei/RQV68OTeFPoGnhwA4evIoy9KX8e2xbwn2CGbxmMXM7DcTnUZ+uyVJ6jwyYc7CvOEzhE2D1xXXOdfZHYJn12bx5qYjTBwQzL9uHYaPux6ASksl/9n1H1Zmr8SgNXBf0n3cEXcHnvrWe7pIkiR1JBnobXE4qE3dBRodnqPHAFBjsbJoeQYbssuYNzaa3187GJ1WQ52tjg/2f8Cbe9/EYrNw44AbWZi4UA5XK0lSl5KB3paSvZiOOfAcFIXW6IXN7uDm17ZxoLiGv8wawi9H98HusLMqZxX/yvwXpeZSJkdO5sHkB4n1jXV16SVJugTJQG+DbecX1J/QE3zrlQDsOFLJvuMnee7GodyUHMGmwk0sTV9KTlUOQ4OG8tzE50gOSXZxqSVJupTJQG+DacPXAHhdPg2AL/YU4WnQMjDyJAu+WcC2om1EGCP4+2V/Z2qfqbLniiRJLicDvTUNZmr3HkNr9MF98GBsdgdf7S0isv9X3L5uAz5uPjw+4nHmDJyDXqt3dWklSZIAGeitEnmbqC3S4TVmKIpGw7accqrtudgc33ND/xt4OOVhfAztm3JOkiSpq8hAb4Xlx9XY67UYr1K7K3655zie/pkYNAZ+m/JbvA3eLi6hJEnSmeQYra2o3bwVAK+Jk7HaHXy1txCD324mRU6SYS5JUrclA72lk0XUHqrGLSoIXVAQWw9XUKPsx0oN02Onu7p0kiRJbZKB3oJ97zrM5QaM48cD8OXuIjwCduFr8GV8+HgXl06SJKltMtBbMH/3uTo70VUz1eaW/XlojfuYFjNN9miRJKlbk4HelMOBKX0vGoMWz+HD2XyoHLM+EwcNsrlFkqRuTwZ6UyV7qc0XeCb0RTEY1OYWv12EG8NJDE50dekkSZLOSgZ6Ew1bVmGt1eE1ZRoNNgfrs3PAM4drY6+VT4JKktTtyUBvwvTDdwAYr7iGzYfLqTOkAYJrY9uefk6SJKm7kIF+SoOZ2n0F6AO9MPTpw5e7i3D3yyQuIE6OnihJ0kVBBnojcfhHakv0eI0arja3HMwEt0Ku63vduQ+WJEnqBmSgNzJ/9ynCpsE4dTabDpVR756OBg3TYqa5umiSJEntIgO9Ue3WHaABz3ET+HxXIW6+mYwOGyNnHZIk6aIhAx3gZBGmwyY8+4Vhc/fg29ztoK/iun6y77kkSRcPGeiAbefn1J/Q4zXxMn46WE6DRxoGjTtTIqe4umiSJEntJgMdqP32CwC8pl7P57uPYfDZw+VRU/DUe7q4ZJIkSe0nA93hwJSRjdZLDwMG8d3RH0Fbx4x+sneLJEkXl3YFuqIo0xRFyVYU5ZCiKE+0sn2hoih7FEXJVBRlk6IocR1f1M4hinZTWyDwGjaInw5VYPNMw1vvz+iw0a4umiRJ0nk5Z6AriqIFXgauBuKAW1oJ7P8KIRKEEEnAc8DSDi9pJ7FsXKnOTnTldFbvPoTeO4vpfa9Bp5GTOUmSdHFpTw19JHBICJErhGgAVgAzm+4ghDjZZNELEB1XxM5V++MPAOgmTuWHgu9AsTNTPkwkSdJFqD3V0HAgv8lyATCq5U6KotwHPAwYgFa7hyiKsgBYABAVFXW+Ze14DWZqs4pxCw9iU6XA4ZVOmEckcYEXTYuRJEmSU4fdFBVCvCyE6As8Dvy+jX1eE0KkCCFSgoODO+rSP5s963vMZTqMY0byya496LyOcH3/6+TIipIkXZTaE+iFQGST5YjGdW1ZAcy6kEJ1FfM3n4BQ0F95PZuLvwGQDxNJknTRak+gpwL9FUWJURTFANwMrGm6g6Io/ZssXgvkdFwRO0/t9p0oeoVt3jEIr53EescT6R157gMlSZK6oXO2oQshbIqi3A+sB7TAW0KIfYqiPAOkCSHWAPcrinIFYAWqgLmdWegOcbII0xEzXnF9+SgrA617CXMG3+3qUkmSJP1s7eqbJ4RYC6xtse4PTd4/0MHl6nQNWz7BatLhM34yqWXfovXXco0cWVGSpIvYJfukqOm7rwDI6D8RjBkMDRiFn7ufi0slSZL0812age5wUJt5CL2/O++W5qDRn+S2Ide7ulSSJEkX5JIMdFGQibkI3IfHsat6Azo8mBx5mauLJUmSdEEuyUA3f70Ch01DTtw4FK89jAqZhLvO3dXFkiRJuiCXZKDXbt4EGnjD0ICirWdugmxukSTp4nfpBXqDGdOBMtyjA8ls2IK7EsDIsBGuLpUkSdIFu+QC3Za5jvoqHSWD41G8srks/Cq0Gq2riyVJknTBLrlAr/36UwA+CDaiKA5+lXSji0skSZLUMS65Qb9NqbvRemrZ6HsAX20UgwMHurpIFxWr1UpBQQEWi8XVRZGkHs3d3Z2IiAj0en27j7mkAl2cKKQ2z0LNgCgUz2NMjbrH1UW66BQUFODt7U10dLQclVKSOokQgoqKCgoKCoiJiWn3cZdUk0v9hhXY67Wsj/ABoXD3sBtcXaSLjsViITAwUIa5JHUiRVEIDAw877+EL6lAN21Qh8hd26ecYP1genuHubhEFycZ5pLU+X7O/7NLJ9AdDmp3H6Eh2I1q/yqm95XjnkuS1LNcMoHuyEvFXKqQFm0EoeOupBmuLpL0M1RUVJCUlERSUhKhoaGEh4c7lxsaGs56bFpaGosWLTrnNcaOHdtRxQXgwQcfJDw8HIfD0aHn7SqrV6/mmWeeAWDx4sV4enpSWlrq3G40Gs/rfNHR0UyYMKHZuqSkJIYMGXLhhf0Z8vLy+O9//9th59uzZw/z5s3rsPOdj0sm0GvXLgeHwrcxdUS4JePn7uvqIkk/Q2BgIJmZmWRmZrJw4UIeeugh57LBYMBms7V5bEpKCi+++OI5r7Fly5YOK6/D4WDVqlVERkbyww8/dNh5Wzrb575Qzz33HL/+9a+dy0FBQfzzn/+8oHPW1NSQn69OVZyVlXVB57pQHR3oCQkJFBQUcOzYsQ47Z3tdMr1cardsw6GDA33quW+ArJ13hD99vo/9x0926Dnjevvwx+viz+uYefPm4e7uTkZGBuPGjePmm2/mgQcewGKx4OHhwdtvv83AgQPZuHEj//jHP/jiiy9YvHgxx44dIzc3l2PHjvHggw86a+9GoxGTycTGjRtZvHgxQUFB7N27l+TkZD744AMURWHt2rU8/PDDeHl5MW7cOHJzc/niiy/OKNvGjRuJj49nzpw5LF++nMmTJwNQUlLCwoULyc3NBeCVV15h7NixvPfee/zjH/9AURSGDh3K+++/z7x585g+fTo33njjGeV7+umn8ff358CBAxw8eJBZs2aRn5+PxWLhgQceYMGCBQCsW7eOJ598ErvdTlBQEN988w0DBw5ky5YtBAcH43A4GDBgAFu3bqXpfL8HDx7Ezc2NoKAg57q77rqLd955h8cff5yAgIBmn3fp0qW89dZbANx99908+OCDrf7MfvGLX/DRRx/xyCOPsHz5cm655Rbef/99QL3xfu+995KWloZOp2Pp0qVMnjyZd955h9WrV1NbW0tOTg6PPPIIDQ0NvP/++7i5ubF27VoCAgI4fPgw9913H2VlZXh6evL6668zaNAg5s2bh4+PD2lpaRQXF/Pcc89x44038sQTT5CVlUVSUhJz587F39+ftLQ0/vWvfwEwffp0HnnkESZNmoTRaOTee+9l7dq1hIWF8eyzz/LYY49x7Ngxli1bxowZarZcd911rFixgscee+x8/ilfsEujht5gxnSwktxIA3aNF3ckyoksepqCggK2bNnC0qVLGTRoED/99BMZGRk888wzPPnkk60ec+DAAdavX8+OHTv405/+hNVqPWOfjIwMli1bxv79+8nNzWXz5s1YLBbuuecevvrqK9LT0ykrK2uzXKfCavbs2Xz55ZfOayxatIjLLruMXbt2sXPnTuLj49m3bx9/+ctf+P7779m1axcvvPDCOT/3zp07eeGFFzh48CAAb731Funp6aSlpfHiiy9SUVFBWVkZ8+fP55NPPmHXrl2sXLkSjUbDL3/5Sz788EMAvv32WxITE2k5efvmzZsZPnx4s3VGo5G77rrrjPKlp6fz9ttvs337drZt28brr79ORkZGq+W+4YYb+PRT9SG/zz//nOuuu8657eWXX0ZRFPbs2cPy5cuZO3eus7fH3r17+fTTT0lNTeWpp57C09OTjIwMxowZw3vvvQfAggULeOmll0hPT+cf//hHs78uioqK2LRpE1988QVPPPEEAEuWLGHChAlkZmby0EMPnfX7XVtby5QpU9i3bx/e3t78/ve/55tvvmHVqlX84Q/OOX9ISUnhp59+Ouu5OsMlUUNv2PYZVpOWn0Y76Os5DoPO4Ooi9QjnW5PuTDfddBNarTqEQ3V1NXPnziUnJwdFUVoNaoBrr70WNzc33Nzc6NWrFyUlJURERDTbZ+TIkc51SUlJ5OXlYTQaiY2NdfYPvuWWW3jttdfOOH9DQwNr165l6dKleHt7M2rUKNavX8/06dP5/vvvnQGk1Wrx9fXlvffe46abbnLWhlvWflszcuTIZv2UX3zxRVatWgVAfn4+OTk5lJWVMXHiROd+p8571113MXPmTB588EHeeust7rzzzjPOX1RUdEbIg/oLKSkpiUceecS5btOmTcyePRsvLy8Arr/+en766SeGDRt2xvGBgYH4+/uzYsUKBg8ejKenZ7Pz/OY3vwFg0KBB9OnTx/kLa/LkyXh7e+Pt7Y2vr6/zF0FCQgK7d+/GZDKxZcsWbrrpJuf56uvrne9nzZqFRqMhLi6OkpKSs35vW2MwGJg2bZrzmm5ubuj1ehISEsjLy3Pu16tXL44fP37e579Ql0Sgm77+DIDMWMGvBs9ycWmkznAqRACefvppJk+ezKpVq8jLy2PSpEmtHuPm5uZ8r9VqW22Hbs8+bVm/fj0nTpwgISEBALPZjIeHB9Onn18PK51O57yh6nA4mt38bfq5N27cyLfffsvWrVvx9PRk0qRJZ+3HHBkZSUhICN9//z07duxw1tab8vDwoLq6+oz1fn5+3Hrrrbz88svn9VmamjNnDvfddx/vvPNOu49p+vPQaDTOZY1Gg81mw+Fw4OfnR2Zm5jmPF0K0uk/T7zfQ7Huo1+ud3Qlbu37TYzw8PNr9uTrKJdHkUpu+jxM+CsU+Adw0ZLyriyN1surqasLDwwHOKyzaa+DAgeTm5jprZB999FGr+y1fvpw33niDvLw88vLyOHLkCN988w1ms5nLL7+cV155BQC73U51dTVTpkxh5cqVVFRUAFBZWQmovULS09MBWLNmTZt/cVRXV+Pv74+npycHDhxg27ZtAIwePZoff/yRI0eONDsvqO3cv/zlL5v9hdPU4MGDOXToUKvXe/jhh3n11VedQTZhwgRWr16N2WymtraWVatWndGbpanZs2fz2GOPMXXq1GbrJ0yY4PzlcvDgQY4dO8bAge0bosPHx4eYmBhWrlwJqKG9a9eusx7j7e1NTU2Nczk6OprMzEwcDgf5+fns2LGjXddu6uDBgy7ptdPjA11UHKM2v4EdfSHOdzIaTY//yJe8xx57jN/97ncMGzasU3p/eHh48O9//5tp06aRnJzs/PO/KbPZzLp167j22mud67y8vBg/fjyff/45L7zwAhs2bCAhIYHk5GT2799PfHw8Tz31FJdddhmJiYk8/PDDAMyfP58ffviBxMREtm7d2qxW3tS0adOw2WwMHjyYJ554gtGjRwMQHBzMa6+9xvXXX09iYiJz5sxxHjNjxgxMJlOrzS0AEydOJCMjo9XabFBQELNnz3Y2aQwfPpx58+YxcuRIRo0axd13391qc8sp3t7ePP744xgMzZtAf/3rX+NwOEhISGDOnDm88847zWrW5/Lhhx/y5ptvkpiYSHx8PJ999tlZ9x86dCharZbExESef/55xo0bR0xMDHFxcSxatOiMewjtsWHDhmY/+y4jhHDJV3JysugKpg+fFfsHDhJ3PhknvszK6JJr9mT79+93dRG6hZqaGiGEEA6HQ9x7771i6dKlLi7Rz5OamirGjx9/1n0WLVokvvnmmy4q0cXPYrGIUaNGCavVesHnau3/G5Am2sjVHl9drf3he+wayAqL4OqBia4ujtRDvP766yQlJREfH091dTX33HPxDfS2ZMkSbrjhBv7617+edb8nn3wSs9ncRaW6+B07dowlS5ag03X9LUpFtHFjoLOlpKSItLS0zr2Iw0HWxDj2eyisWfgr3r3hkXMfI51VVlYWgwcPdnUxJOmS0Nr/N0VR0oUQKa3t36Nr6LYDm6BcYVeMhruT5LyhkiT1bD060E1frgAgOyKS8bHtH1NYkiTpYtSj+6Ef27adOg/wi58lh3yVJKnHa1cNXVGUaYqiZCuKckhRlCda2f6woij7FUXZrSjKd4qi9On4op4fYTFhO1LLnmiF+SkzXV0cSZKkTnfOQFcURQu8DFwNxAG3KIoS12K3DCBFCDEU+Bh4rqMLer5MGz7Cw6xwJKIXyVGhri6O1EHk8LldRwhBUFAQVVVVgDoMgKIobNq0yblPcHAwFRUV3H333ezfvx+AZ5991rk9Ly+vXQ/YLF68GEVRmj3EtGzZMhRFodM7T7Rh2bJlF13vnvbU0EcCh4QQuUKIBmAF0KzKK4TYIIQ49cm3ARG42O51avs5KTfJ5pYeRA6f27rOeIBKURRGjx7N1q1bAfX7MmzYMOf3Jzs7m8DAQAIDA3njjTeIi1PreU0D/XwkJCSwYsUK5/LKlSuJj3fdeEE9NdDDgfwmywWN69ryK+Cr1jYoirJAUZQ0RVHSzjZCXUcw7yskPxhuvvyWTr3OJe2rJ+Dtazv266szWvTOad68eSxcuJBRo0bx2GOPsWPHDsaMGcOwYcMYO3Ys2dnZgDrWyalxVBYvXsxdd93FpEmTiI2NbRb0pyZs2LhxI5MmTeLGG29k0KBB3Hbbbc4nJteuXcugQYNITk5m0aJFbY7Pcmr43HvvvZfly5c715eUlDB79mwSExNJTEx0huR7773H0KFDSUxM5Pbbb3d+vo8//rjV8k2YMIEZM2Y4w3TWrFkkJycTHx/fbMCwdevWMXz4cBITE7n88stxOBz079/fOVKkw+GgX79+Z4wcOXbsWGfZtmzZwkMPPdQs4MeNGwfApEmTSEtL44knnqCuro6kpCRuu+02QB3aYP78+cTHx3PVVVdRV1fX6vdq1qxZzqc6Dx8+jK+vb7Nhe5cvX05CQgJDhgzh8ccfb/b9ePTRR4mPj+eKK65gx44dzp/rmjVrnGV49NFHGTFiBEOHDuXVV18968/4xRdf5Pjx40yePNk55HHTiTw+/vhj5yQW8+bN495772X06NHExsayceNG7rrrLgYPHtzlE110aC8XRVF+CaQAf29tuxDiNSFEihAipbUR3DrKiWO7CD0uyI/0YUi4f6ddR+o+5PC5nTN87rhx45yBvmPHDmbPnu2cmGLLli1nNE8tWbIEDw8PMjMznefOycnhvvvuY9++ffj5+fHJJ5+0+ll8fHyIjIxk7969rFixotkQBcePH+fxxx/n+++/JzMzk9TUVFavXg20b0jbN998E19fX1JTU0lNTeX11193jm3T2s940aJF9O7dmw0bNrBhw4Zz/hyqqqrYunUrzz//PDNmzOChhx5i37597Nmzp82BwjpDe3q5FAKRTZYjGtc1oyjKFcBTwGVCiPqW27vSpv/9g74OEEMvl80tnenqJa4ugZMcPlfV0cPnjhgxgoyMDGpra7Farc7PfujQIbZs2cJvf/vbc5YxJiaGpKQkAJKTk5sNM9vSzTffzIoVK1i/fj3fffcdb7/9NgCpqalMmjTJ+Qvntttu48cff2TWrFntGtL266+/Zvfu3c6/dKqrq8nJycFgMLT6Mx4//vwG8bvuuutQFIWEhARCQkKcI2zGx8eTl5fn/PydrT2Bngr0VxQlBjXIbwZubbqDoijDgFeBaUKI0jNP0bUq03cToYOxcx5wdVGkLiKHz+2c4XM9PT3p378/b731lnOQqtGjR7N27VpKS0vbNQpiy+9hW00uoM4O9Oijj5KSkoKPj885zw3tG9JWCMFLL710xsiOGzdubPfPuGnlsOX3tek1Ww7x25nTA7Z0ziYXIYQNuB9YD2QB/xNC7FMU5RlFUU7N5fZ3wAisVBQlU1GUNZ1W4nMoqikkIq+B0t4GBkf3clUxJBeSw+d23PC5oLajL1u2jDFjxgAwZswYXnjhBUaPHt3qX8B6vb7NMp6Lp6cnf/vb33jqqaearR85ciQ//PAD5eXl2O12li9fzmWXXdbu806ddj1FlQAAFCFJREFUOpVXXnnFWa6DBw9SW1t71mNaDqsbEhJCVlaW80Z3d9SuNnQhxFohxAAhRF8hxP81rvuDEGJN4/srhBAhQoikxi+XTdr55bplhFWBGDRENrdcouTwuR03fC7gnDP1VKAPHz6cgoKCNrt3LliwgKFDhzpvip6vm2+++Ywha8PCwliyZAmTJ08mMTGR5ORkZs5s//Mld999N3FxcQwfPpwhQ4Zwzz33nPPfxoIFC5g2bZrzpuiSJUuYPn06Y8eOJSws7Pw/WBfoUYNzCSH484Mp3LTejO61/9B/Yvt/g0vtIwfnUplMJoxGI0II7rvvPvr373/O+Si7o7S0NB566CGXzH8pndslPTjXwaqDROfWUecNfce3PVOKJF2oS2n4XOni0aNq6H/5//buPSrqOv/j+PPtBREwMS2yxV9gq3EbuYiIGK5sN229UV5z+0ms665ZbGyZ/mpPduzUwc1VWtfjsSLZ05akZqy3XStTU6kcEQSVREFCgrytmoomwuf3x8B3ucogA+MMn8c5HpnvfL/feX9n4D0z38vrs+M1Rid8CH53MXhN86caaS2nP6FrWvtp6Sd0pwnnqqyqpGD3BtyugWvMw/YuR9M0rd05zS6XfSf38fPCyyhR/M+U39i7HE3TtHbnNA197bf/JLRQIV7d6Hy7Pl1R07SOxyka+tXrV9n37af4/KBwC7NfmI+maZo9OUVD31GyA7/jVxCEO8dNsnc5WhuKiYlh69atdaYlJycze/bsJpepCY4CePTRRzl//nyDeV599VUWL158w8dOT083ImIBXnnlFT7//POWlH9DjhqzWyM9PZ2FCxcClufTzc2NU6f+e+F47XAra/j4+BAdXfdstZCQEKvieNtCUVERH374oc3Wl5uba/PwLqdo6B8f2UB4AXTqpnAd3rLLqjXHMm3atDoRqwBpaWlMm2ZdquaWLVvw9PS8qceu39AXLlzIgw8+eFPrqs+RY3Zr/PnPf+bpp582bvfp04e//OUvrVrnxYsXjTCwvLy8Vq2rtWzd0E0mEyUlJRQXF9tsnQ7f0M9dPYe5bA+DCyvp9vM+SNeu9i6pw1i0dxFP/fspm/5btHfRDR9z4sSJbN682cgzKSoqorS0lOjoaGbPnk14eDiBgYEsWLCg0eV9fHw4c+YMAK+//joDBw7k/vvvNyJ2wXKO+ZAhQwgODubxxx+nvLycjIwMNmzYwNy5cwkJCaGgoKBOrO22bdsIDQ3FZDIRHx/PTz/9ZDzeggULCAsLw2Qy8e233zZal6PH7Obn59OtW7c6cbfx8fF89NFHdaIGaixZsoSgoCCCgoJITk5u9DkBmDx5shGtUJNcWePq1as89dRTmEwmQkNDjVTE1NRUJkyYwEMPPYSPjw9/+9vfWLJkCaGhoURGRhr1FBQUGFf7RkdHG69NXFwcCQkJREVF0b9/f+M5nT9/Prt27SIkJISlS5eSmprKM888Y9QzZswYduzYYTz3zUX6giXUq/4HlNZw+Ia+tWgr3qcqcb0ieI5oWUKa5nhuv/12IiIi+Ne/LJH7aWlpTJ48GRHh9ddfZ9++feTk5LBz505ycnKaXE9mZiZpaWlkZ2ezZcsWzGazcd9jjz2G2WzmwIED+Pv7k5KSQlRUFOPGjePNN98kOzube++915j/6tWrxMXF8dFHH5Gbm8v169eNnBawfFLdv38/s2fPbnK3jqPH7O7Zs6fB5foeHh7Ex8c3qC8zM5NVq1bxzTff8PXXX/POO++QlZXVaN2PP/4469evB2Djxo2MHTvWuG/58uWICLm5uaxevZoZM2YYoVkHDx5k/fr1mM1mXn75Zdzc3MjKymLYsGFGyuWsWbNYtmwZmZmZLF68uM63i7KyMnbv3s2mTZuYP9+S0Z+UlER0dDTZ2dnNXhVsTaQvWAZdseVVug5/HvonRzcSmd8FqMR97K/tXU6HMi9iXvMztYGa3S7jx48nLS2NlJQUANasWcPbb7/N9evXKSsr4/DhwwwaNKjRdezatYvY2Fjc3NwAS6ZJjYMHD/KnP/2J8+fPc+nSpQYJffUdOXIEX19fBg4cCMCMGTNYvnw5zz33HGB5gwBLdGxNc6rNGWJ2y8rKGjR5sLwhhYSE8MILLxjTdu/eTWxsrJFJ89hjj7Fr1y5CQ0MbLN+7d2969epFWloa/v7+xutVs55nn30WAD8/P+655x7jDSsmJoYePXoYOTs1bwQmk4mcnBwuXbpERkYGkyb995hbzbcqsHyD6dSpEwEBAZw8efKGz21jrIn0BbjzzjspLS1t8fqb4tAN/cTFExz+Tw6zC6pw6d2Jrv3tc7BEa1/jx48nMTGR/fv3U15ezuDBgzl+/DiLFy/GbDbTq1cv4uLibhgdeyNxcXGkp6cTHBxMamqq8TX6ZtXEqTYVzeoMMbvdu3fnwoULDaZ7enryxBNPsHz58hZtS21Tpkxhzpw5LUrOrB9hWz9St6qqCk9PzyYHn6i9fFNX09d+vqFupK41kb41y3Tv3t3q7WqOQ+9y2Vy4mW7XFF4nK/EIvrf5BTSn4OHhQUxMDPHx8cY+1R9//BF3d3d69uzJyZMnjV0yTRkxYgTp6elcuXKFixcvsnHjRuO+ixcv0rdvXyoqKuo0r/pxqjXuu+8+ioqKjAGO33///RZFuzpDzK6/v3+dAZ5r++Mf/8jKlSuNRhYdHU16ejrl5eVcvnyZTz75pMHZLLXFxsby4osvNvimFB0dbbw++fn5FBcXW5XPDpbRkXx9fVm7di1gadoHDhy44TL1X38fHx+ys7OpqqrixIkT7N2716rHri0/P9+mZ+04bENXSpF+dCPh+T2hSvD45Sh7l6S1o2nTpnHgwAGjoQcHBxMaGoqfnx9PPPGEMdZlU8LCwpgyZQrBwcGMHj2aIUOGGPe99tprDB06lOHDh+Pn52dMnzp1Km+++SahoaEUFBQY011dXVm1ahWTJk3CZDLRqVMnfv/731u1Hc4SsztixAiysrIa/TTbp08fYmNjjV0aYWFhxMXFERERwdChQ5k5c2aju1tq9OjRg3nz5uHi4lJn+tNPP01VVRUmk4kpU6aQmppa55N1cz744ANSUlIIDg4mMDDQGM+0KYMGDaJz584EBwezdOlShg8fjq+vLwEBASQkJDQ4hmCN7du313ntW00pZZd/gwcPVq2RezpXBaUGqTUTwlVewH2q8tL5Vq1Ps87hw4ftXYJmB2azWd1///03nCchIUF99tln7VSR47t69aoaOnSoqqioaHKexv7egH2qib7qsJ/QNxVuAtWFwJJLuPl40Mm9Z/MLaZrWYtbG7L700kuUl5e3U1WOr7i4mKSkJLp0sd2hTIds6BVVFWwq2MJd33sjF8Ejon0GYNW0jmj+/Pl89913zQ6c7OXlVedsIe3GBgwY0OR4tzfLIRv616Vfc+HaOUbnWw6yuI/Wl/trmqY5ZEPffHwznZQbI0tP09VD4TLYNpdfa5qmOTKHa+jlFeV8/t02rp8NwO2HS7j790WaGK1c0zStI3G4hr6teBs/VV5l+PFuqArBPXqEvUvSNE27JThcQ+/h0gO3imAmny4GUbiPfdLeJWntSMfn3nqUUvTp04dz584BlhgAEWH37t3GPHfccQdnz55l5syZxnP4xhtvGPcXFRVZdYHNq6++iojUuYgpOTkZEcHWYxRbKzk5+ZY5u8fhGnp/twhOHptGv9ISut/Vhc59f27vkrR2pONzW6ct4nNFhMjISL766isAMjIyCA0NNZIhjxw5Qu/evenduzfvvvuukfhYu6G3hMlkqvM7sHbtWgID7TewjW7orbA5twyvn85Sdfoa7qED7V1Oh/bDG2/w3ZP/a9N/PzTzR67jc2/N+NyoqCijtoyMDBITE+s0+Jord2u+Lc2fP58rV64QEhLC9OnTAUu0wW9/+1sCAwN5+OGHuXLlSqPP1YQJE4yrOgsKCujZs2ed2N7Vq1djMpkICgpi3rz/BshZE2lbWVnJ3LlzGTJkCIMGDWLlypXGczhy5EgmTpyIn58f06dPRynFX//6V0pLS4mJiSEmJqbO8w6wbt06YxCLuLg4Zs+eTWRkJP3792fHjh3Ex8fj7+9vs4EuHK6hjw3uy7Lb8wDB4wEbXjKrOQQdn3trxucOHz7caOh79+4lNjbWGJgiIyODqKioOvMnJSXRvXt3srOzjXUfPXqUOXPmcOjQITw9Pfn4448b3ZbbbruNfv36cfDgQdLS0upEFJSWljJv3jy++OILsrOzMZvNpKenA9ZF2qakpNCzZ0/MZjNms5l33nnHyLbJysoiOTmZw4cPU1hYyJ49e0hISODuu+9m+/btRh77jZw7d46vvvqKpUuXMm7cOBITEzl06BC5ublNBoW1hFWXKInIKOAtoDPwrlIqqd79I4BkYBAwVSm1ruFabMO7lxud8jO55FKF6wNTml9AazN3vfSSXR5Xx+feevG5Q4YMISsri8uXL1NRUYGHhwf9+/fn2LFjZGRk8Pzzzzdbo6+vLyEhIcZzVTtmtr6pU6eSlpbG1q1b2bZtG6tWrQLAbDYzcuRI4w1n+vTpfPnll0yYMMGqSNtPP/2UnJwc45vOhQsXOHr0KC4uLkRERODt7Q1YhsIrKipq9mKr+saOHYuIYDKZ8PLyMhI2AwMDKSoqMrb/ZjXb0EWkM7AceAgoAcwiskEpdbjWbMVAHPBCwzXYllKKS4dKcL+3J+LasjEKNeeg43MbZ8/4XDc3NwYMGMB7771nhFRFRkayZcsWTp06ZVUKYu1grc6dOze5ywUsowPNnTuX8PBwbrvttmbXDdZF2iqlWLZsWYM38R07djSor6njETWPATR4Xms/Zv2IX1sc37Bml0sEcEwpVaiUugakAeNrz6CUKlJK5QBtfnj+p8zdVJYr3CMHt/VDabcoHZ9768XngmU/enJyMsOGDQNg2LBhvPXWW0RGRtZpcjW6du3aZI3NcXNzY9GiRbz88st1pkdERLBz507OnDlDZWUlq1evbtFr8cgjj7BixQqjrvz8fC5fvnzDZer/Xnh5eZGXl2cc6G5P1jT0nwEnat0uqZ7WYiIyS0T2ici++gdVrHV5s+Xotvuvpt7U8ppz0PG5t1Z8Llj2oxcWFhoNPSwsjJKSkgb7z2vMmjWLQYMGGQdFW2rq1KkNImv79u1LUlISMTExBAcHM3jwYMaPH9/EGhqaOXMmAQEBhIWFERQUxO9+97tmPznPmjWLUaNGGQdFk5KSGDNmDFFRUfTt27flG9YKopoYjcOYQWQiMEopNbP69pPAUKXUM43MmwpssmYfenh4uLqZ80av7Xyf8n99gOcbW6CTwx3TdXh5eXn4+/vbuwytne3bt4/ExESbjn+pNa+xvzcRyVRKhTc2vzUHRb8H+tW67V09zS5cfvEkLr/QFxNpWntJSkpixYoVje47124t1nzENQMDRMRXRFyAqcCGti1L07RbhbXxuZr9NdvQlVLXgWeArUAesEYpdUhEForIOAARGSIiJcAkYKWIHGrLojX7am43naZprXczf2dWnYeulNoCbKk37ZVaP5ux7IrRnJyrqytnz56ld+/ejZ65oGla6ymlOHv2LK6uri1aznZjH2kdgre3NyUlJQ0u/dY0zbZcXV2NC5mspRu61iJdu3atc8Whpmm3Dn3en6ZpmpPQDV3TNM1J6IauaZrmJJq9UrTNHljkNPDdTS7eBzhjw3Icgd7mjkFvc8fQmm2+Ryl1R2N32K2ht4aI7Gvq0ldnpbe5Y9Db3DG01TbrXS6apmlOQjd0TdM0J+GoDf3t5mdxOnqbOwa9zR1Dm2yzQ+5D1zRN0xpy1E/omqZpWj26oWuapjkJh2voIjJKRI6IyDERmW/vetqaiPQTke0iclhEDonIH+xdU3sQkc4ikiUim+xdS3sQEU8RWSci34pInogMs3dNbU1EEqt/pw+KyGoRaVm0oAMQkfdE5JSIHKw17XYR+UxEjlb/38tWj+dQDV1EOgPLgdFAADBNRALsW1Wbuw48r5QKACKBOR1gmwH+gCV/v6N4C/i3UsoPCMbJt11EfgYkAOFKqSCgM5bBc5xNKjCq3rT5wDal1ABgW/Vtm3Cohg5EAMeUUoVKqWtAGmD9CLAOSClVppTaX/3zRSx/6Dc1SLejEBFv4FfAu/aupT2ISE9gBJACoJS6ppQ6b9+q2kUXoLuIdAHcgFI712NzSqkvgf/Umzwe+Hv1z38HJtjq8Rytof8MOFHrdglO3txqExEfIBT4xr6VtLlk4EWgyt6FtBNf4DSwqno307si4m7votqSUup7YDFQDJQBF5RSn9q3qnbjpZQqq/75B8DLVit2tIbeYYmIB/Ax8JxS6kd719NWRGQMcEoplWnvWtpRFyAMWKGUCgUuY8Ov4bei6v3G47G8md0NuIvIr+1bVftTlvPGbXbuuKM19O+BfrVue1dPc2oi0hVLM/9AKbXe3vW0seHAOBEpwrJL7Zci8g/7ltTmSoASpVTNN691WBq8M3sQOK6UOq2UqgDWA1F2rqm9nBSRvgDV/5+y1YodraGbgQEi4isiLlgOomywc01tSiwDd6YAeUqpJfaup60ppf5PKeWtlPLB8vp+oZRy6k9uSqkfgBMicl/1pAeAw3YsqT0UA5Ei4lb9O/4ATn4guJYNwIzqn2cA/7TVih1qCDql1HUReQbYiuWo+HtKqUN2LqutDQeeBHJFJLt62kvVA3drzuNZ4IPqDyqFwFN2rqdNKaW+EZF1wH4sZ3Jl4YQRACKyGhgJ9BGREmABkASsEZHfYIkQn2yzx9OX/muapjkHR9vlommapjVBN3RN0zQnoRu6pmmak9ANXdM0zUnohq5pmuYkdEPXNE1zErqha5qmOYn/B6FgRib1n04MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poopjZb0yVJS"
      },
      "source": [
        "It looks like the model with momentum trains quicker, and the ultimate validation accuracy is higher on the model with momentum as well."
      ]
    }
  ]
}